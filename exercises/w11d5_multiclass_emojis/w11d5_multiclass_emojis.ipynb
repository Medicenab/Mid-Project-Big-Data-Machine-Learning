{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05761ff7-94d2-40cb-baa7-883b2e4e77a9",
   "metadata": {},
   "source": [
    "![](https://api.brandy.run/core/core-logo-wide)\n",
    "\n",
    "# Supervised Learning: Emojis Multiclass\n",
    "\n",
    "Vamos ver un ejemplo más complejo con un modelo del tipo multioutput, en que la respuesta de una predicción no es un único valor, sino que un vector. Te auxiliaremos con parte del processo. Todas las celdas que requieren que escribas algo de código están propriamente identificadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0381d8a8-d67c-4c48-b512-7a0950a65e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9917a9ea-f07d-4109-be92-911ba972e955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos una variable `size` que en lugar de escribirla en cada instancia en que sea necesaria. \n",
    "# Eso nos permite con mayor facilidad entrenar nuestro modelo con imagenes mayores o menores.\n",
    "# Puedes eligir y probar otros valores para ese parámetro. Las imagenes originales posén (72,72).\n",
    "# Acuerdate que más pixeles son más features y en ese caso más modelos, con lo cual subir mucho ese \n",
    "# valor puede resultar en modemos que tarden mucho en el entrenamiento.\n",
    "\n",
    "size = (24,24)\n",
    "pixels = size[0]*size[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d19a9999-8449-4fb4-a04a-0a77c193f5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = [], []\n",
    "for folder in [\"Google\",\"Facebook\",\"Apple\",\"Samsung\",\"Windows\"]:\n",
    "    files = listdir(f\"./emojis/{folder}\")\n",
    "    for file in files:\n",
    "        if file == \".DS_Store\":\n",
    "            continue\n",
    "        path = f\"./emojis/{folder}/{file}\"\n",
    "        \n",
    "        # Abrimos cada imagen, escalando su tamaño al `size` eligido y convertiendo a RGB.\n",
    "        # La conversión a RGB remueve la transparéncia\n",
    "        color = Image.open(path).resize(size).convert(\"RGB\")\n",
    "        \n",
    "        # También hacemos una copia en escale de gris del imagen.\n",
    "        b_n_w = color.convert(\"L\")\n",
    "        \n",
    "        # Por último añadimos las imagenes a nuestras variables X y y.\n",
    "        y.append(np.array(color))\n",
    "        X.append(np.array(b_n_w))\n",
    "X,y = np.array(X),np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6704c32-a67d-4d4d-b1c7-195ad35a7c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "emoji_number = 0\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(X[emoji_number],cmap=\"gray\")\n",
    "plt.title(\"X\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(y[emoji_number])\n",
    "plt.title(\"y\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ee964a-055c-44bd-8029-82b8ec5689fb",
   "metadata": {},
   "source": [
    "## Step 1. Preparing Data\n",
    "\n",
    "Como puedes ver por nuestra definición de X e y, intentaremos entrenar un modelo que sea capaz de colorear un emoji en blanco y negro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "139c770f-9b83-4fda-a558-19b30c589b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2096, 24, 24)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4f49282-b863-404a-88ef-35b0acbdf075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2096, 24, 24, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6854993-2c44-43bc-a4b6-b7a096249290",
   "metadata": {},
   "source": [
    "Según los shapes de nuestros datos, la X (imagenes en blanco y negro) tiene 3 dimensiones y la y (imagenes en color) tiene 4 (la última siendo los 3 canales RGB). Es necesário que sean matrices bi-dimensionales. Ejecuta un `.reshape` con X para que pase a ser una matriz con `2096` imagenes (filas) con el valor de cada pixel como suas features (columnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d90c10c4-2446-47cd-b4a6-a2d72cac319b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ~~~ Esa celda requiere tu atención ~~~\n",
    "X = X.reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b880e197-c8db-4744-acea-fd80bd5fa1b8",
   "metadata": {},
   "source": [
    "Hazlo apenas para la X, en el caso de las imagenes en color, tendremos que separar los 3 canales y lo haremos despues del `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd991a48-55b7-4e6c-8b8d-bd432e3eee68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for channel, color in enumerate([\"red\",\"green\",\"blue\"]):\n",
    "    plt.subplot(1,3,channel+1)\n",
    "    single_channel_image = y[0,:,:,channel]\n",
    "    plt.imshow(single_channel_image, cmap=color.title()+\"s\")\n",
    "    plt.title(color)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e575f9b2-5f3c-4111-9085-f1a3b05207a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9da3982-c4e4-4608-b8b1-07511ba9447b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Singleton array array(<built-in method reshape of numpy.ndarray object at 0x7fe3a3f90bd0>,\n      dtype=object) cannot be considered a valid collection.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-705915f25b8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2415\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"At least one array required as input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2417\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    327\u001b[0m     \"\"\"\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    327\u001b[0m     \"\"\"\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m             raise TypeError(\n\u001b[0m\u001b[1;32m    270\u001b[0m                 \u001b[0;34m\"Singleton array %r cannot be considered a valid collection.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             )\n",
      "\u001b[0;31mTypeError\u001b[0m: Singleton array array(<built-in method reshape of numpy.ndarray object at 0x7fe3a3f90bd0>,\n      dtype=object) cannot be considered a valid collection."
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137712b7-0250-472f-a55c-9d0e2a9756e1",
   "metadata": {},
   "source": [
    "Ahora que tenemos los datos divididos en Train y Test, debemos separar los canales de cada imagen (como hizo el el plot arriba para ilustrar la decomposición). Escribe el código necesário para que las variables `y_train` e `y_test` tengan el formato ilustrado abajo, donde cada lista vacia es un numpy array con la misma cantidad de imagenes (1572 en train, 524 en test) y los pixeles como columnas. Pero que cada value del diccionario tenga apenas los valores del canal correspondiente.\n",
    "\n",
    "```python\n",
    "y_train = {\n",
    "    \"red\": [],\n",
    "    \"blue\": [],\n",
    "    \"green\": []\n",
    "}\n",
    "\n",
    "y_test = {\n",
    "    \"red\": [],\n",
    "    \"blue\": [],\n",
    "    \"green\": []\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e64bcd-f4b8-4e7c-8109-4a68d57f0dfe",
   "metadata": {},
   "source": [
    "## Step 2. Training Model\n",
    "\n",
    "Tenemos un problema del tipo multioutput, pero el modelo que vamos utilizar es la Regresión Lineal, que no es directamente competible con ese tipo de problema. Para eso usaremos el `MultiOutputRegressor`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c703497f-e634-426f-a35c-44fdcc71c445",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9906e611-53ed-4b4e-8e65-b1ceac8d12f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizaremos 3 modelos, uno para cada canal.\n",
    "# El parámetro `n_jobs` indica cuantos nucleos de cpu se deben utilizar para entrenar y predecir. \n",
    "# Si le definimos como -1 se usaran todos que estén disponíbles\n",
    "\n",
    "model = {channel:MultiOutputRegressor(LinearRegression(), n_jobs=-1) for channel in [\"red\",\"green\",\"blue\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309f51e0-abd8-46b0-bd24-08584a4e8976",
   "metadata": {},
   "source": [
    "Escribe un bucle para entrenar cada modelo con los datos apropriados!\n",
    "\n",
    "Todos utilizaran la misma X, pero cada uno tendrá su `y` especifica, guardada en el dicionário que definimos previamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5efff51-cb5e-43e5-b434-80885006019f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ~~~ Esa celda requiere tu atención ~~~\n",
    "\n",
    "# Train model here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90113858-5d58-4633-be6a-e8b0886e7eef",
   "metadata": {},
   "source": [
    "## Step 3. Predicting\n",
    "\n",
    "A partir de aqui puedes simplemente ejecutar las celdas y disfrutar. Investiga el codigo y como funciona cada celda! Toca y prueba. \n",
    "\n",
    "Como tenemos 3 modelos entrenados separadamente para los 3 canales, también tendremos que hacer 3 prediciones y recomponerles en una única imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdacd2fd-f0cc-472c-9f99-0b28d4f7b2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_pred = {\n",
    "    channel : model[channel].predict(X_test).reshape(X_test.shape[0],*size) for channel in [\"red\",\"green\",\"blue\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9969056-fac9-492b-984f-7dc6fe5770a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose_picture(r,g,b):\n",
    "    image = np.stack([r,g,b], axis = -1) \n",
    "    # We change negative pixel values into 0. Negatives come from the prediction\n",
    "    image = np.where(image < 0, 0, image)\n",
    "    # We make it so individual pixel values are between 0 and 1\n",
    "    image = image/image.max()\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b337f5d7-9a3e-4a3d-938a-cc3bf03cd9c5",
   "metadata": {},
   "source": [
    "## Printing One Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6462a0d9-2f37-402c-8812-b93a2f60e853",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_number = 0\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.subplot(1,6,1)\n",
    "plt.imshow(X_test[image_number].reshape(*size), cmap=\"gray\")\n",
    "plt.title(\"X_test\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "for i, channel in enumerate([\"red\",\"green\",\"blue\"]):\n",
    "    plt.subplot(1,6,i+2)\n",
    "    plt.imshow(im_pred[channel][image_number].reshape(*size), cmap=channel.title()+\"s\")\n",
    "    plt.title(f\"pred_{channel}\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "plt.subplot(1,6,5)\n",
    "composed_image = compose_picture(*[im_pred[channel][image_number].reshape(*size) for channel in [\"red\",\"green\",\"blue\"]])\n",
    "plt.imshow(composed_image)\n",
    "plt.title(\"pred_comp\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,6,6)\n",
    "original_image = compose_picture(*[y_test[channel][image_number].reshape(*size) for channel in [\"red\",\"green\",\"blue\"]])\n",
    "plt.imshow(original_image)\n",
    "plt.title(\"original\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2e0584-ba16-4a42-9b14-6753f08a3615",
   "metadata": {},
   "source": [
    "## Printing some more examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6e917e-a115-4a56-ae1b-b9d66889f012",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_X = X_test.reshape(X_test.shape[0],*size)\n",
    "images_y = [compose_picture(*[y_test[channel][i].reshape(*size) for channel in [\"red\",\"green\",\"blue\"]]) for i in range(y_test[\"red\"].shape[0])]\n",
    "images_pred = [compose_picture(*[im_pred[channel][i].reshape(*size) for channel in [\"red\",\"green\",\"blue\"]]) for i in range(im_pred[\"red\"].shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc986b7b-37b5-4b3c-9692-476817609789",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = 10\n",
    "\n",
    "plt.figure(figsize=(4,5*n_images))\n",
    "images = [im for tup in (zip(images_X,images_y,images_pred)) for im in tup]\n",
    "titles = [\"Gray\", \"Original\", \"Predicted\"]*n_images\n",
    "for i in range(n_images*3):\n",
    "    plt.subplot(n_images*3,3,i+1)\n",
    "    if titles[i] == \"Gray\":\n",
    "        plt.imshow(images[i], cmap=\"gray\")\n",
    "    else:\n",
    "        plt.imshow(images[i])\n",
    "    plt.title(titles[i])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4508a7-6cb3-4324-bc7f-8a44f5c05bc4",
   "metadata": {},
   "source": [
    "## Step 4. Predicting with images from a different source\n",
    "\n",
    "Ahora es donde verdaderamente testeamos nuestro modelo! Vamos cargar imagenes que el nunca vió y además no tienen el mismo origen que el dataset de train y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823e2fe0-0c8d-4a9f-b405-444c7653391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_images(models, X):\n",
    "    im_pred = {\n",
    "    channel : models[channel].predict(X).reshape(X.shape[0],*size) for channel in [\"red\",\"green\",\"blue\"]\n",
    "}\n",
    "    return np.array([compose_picture(*[im_pred[channel][i].reshape(*size) for channel in [\"red\",\"green\",\"blue\"]]) for i in range(im_pred[\"red\"].shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae1acbf-ed2e-490d-8a42-7453fcbaa5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./test_images\"\n",
    "images = np.array([np.array(Image.open(f\"{path}/{image}.png\").resize(size).convert(\"L\")) for image in range(1,5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e489412d-5e85-4c9b-8020-227958582490",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(images)):\n",
    "    plt.subplot(1,len(images),i+1)\n",
    "    plt.imshow(images[i], cmap=\"gray\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c582237-62a3-44af-bee0-b1fa9f01d4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = predict_images(model, images.reshape(len(images),pixels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6044ed-bed9-4db1-9e9d-4a898f436c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(predicted)):\n",
    "    plt.subplot(1,len(predicted),i+1)\n",
    "    plt.imshow(predicted[i], cmap=\"gray\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018dc6b9-dea5-48de-bdac-1c2e2a86943f",
   "metadata": {},
   "source": [
    "## Keep on Coding!\n",
    "\n",
    "Espero que hayas disfrutado de esa experiencia por el Machine Learning y que veas que simples regresiones lineales pueden abrir las puertas para cosas bastante guays si utilizamos bien las herramientas.\n",
    "\n",
    "Limitamos el dataset en ese ejemplo a emojis que contengan algun tipo de cara, sea de personaje humano o animal. Si quieres, puedes probarlo con todos los emojis. Los datos pueden ser encontrados [aqui.](https://www.kaggle.com/subinium/emojiimage-dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
